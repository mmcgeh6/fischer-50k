---
phase: 03-calculations-narratives
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - lib/waterfall.py
  - app.py
  - requirements.txt
autonomous: false

must_haves:
  truths:
    - "Waterfall executes Steps 4-5 (penalty calc + narratives) after Steps 1-3"
    - "Penalty results are saved to building_metrics via dynamic upsert"
    - "Narrative text is saved to building_metrics via dynamic upsert"
    - "UI penalty tab shows calculated values from database (not empty)"
    - "UI narrative tab shows saved narratives from database (not re-generated each time)"
    - "Narratives use backoff retry for API resilience"
  artifacts:
    - path: "lib/waterfall.py"
      provides: "Extended 5-step waterfall with penalty calc and narrative generation"
      contains: "calculate_ll97_penalty"
    - path: "app.py"
      provides: "UI reads penalty and narrative data from building_metrics"
      contains: "display_penalties"
    - path: "requirements.txt"
      provides: "backoff dependency added"
      contains: "backoff"
  key_links:
    - from: "lib/waterfall.py"
      to: "lib/calculations.py"
      via: "import and call calculate_ll97_penalty"
      pattern: "from lib.calculations import"
    - from: "lib/waterfall.py"
      to: "lib/api_client.py"
      via: "import and call generate_all_narratives"
      pattern: "from lib.api_client import"
    - from: "lib/waterfall.py"
      to: "lib/storage.py"
      via: "upsert penalty and narrative data"
      pattern: "upsert_building_metrics"
    - from: "app.py"
      to: "building_metrics table"
      via: "reads penalty and narrative columns from cached data"
      pattern: "ghg_emissions_2024_2029|envelope_narrative"
---

<objective>
Wire the penalty calculator and narrative generation into the waterfall pipeline as Steps 4-5, persist results to the database, and update the UI to display saved penalty/narrative data.

Purpose: This completes the full 5-step waterfall. Currently the waterfall only runs Steps 1-3 (identity, energy, mechanical). After this plan, it also calculates penalties (Step 4) and generates narratives (Step 5), saving everything to building_metrics. The UI currently shows empty penalty tabs and regenerates narratives every time — after this, both tabs show persisted data.

Output: Extended waterfall in lib/waterfall.py, updated app.py reading from DB, backoff dependency added.
</objective>

<execution_context>
@C:\Users\minke\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\minke\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-calculations-narratives/03-RESEARCH.md
@.planning/phases/03-calculations-narratives/03-01-SUMMARY.md
@lib/waterfall.py
@lib/api_client.py
@lib/storage.py
@lib/calculations.py
@app.py
@CLAUDE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend waterfall with Steps 4-5 and update UI</name>
  <files>lib/waterfall.py, lib/api_client.py, app.py, requirements.txt</files>
  <action>
**1. Add backoff to requirements.txt:**
Add `backoff>=2.2` to requirements.txt. Run `pip install backoff`.

**2. Add retry decorator to lib/api_client.py:**
Import backoff at the top of api_client.py. Add the `@backoff.on_exception(backoff.expo, Exception, max_tries=3, jitter=backoff.full_jitter)` decorator to the `generate_narrative()` function. This handles transient Anthropic API errors and rate limits. Keep the existing per-narrative error handling in `generate_all_narratives()` — the backoff retries individual calls, the try/except catches persistent failures.

**3. Extend lib/waterfall.py with Steps 4 and 5:**

Add imports at top:
```python
from lib.calculations import calculate_ll97_penalty, extract_use_type_sqft
from lib.api_client import generate_all_narratives
```

After Step 3 (Mechanical Retrieval) in `fetch_building_waterfall()`, add:

**STEP 4: LL97 Penalty Calculations**
- Extract energy values from result dict: electricity_kwh, natural_gas_kbtu, fuel_oil_kbtu, steam_kbtu (using `or 0` pattern for None values)
- Extract use-type sqft from result dict using `extract_use_type_sqft(result)`
- Call `calculate_ll97_penalty(electricity_kwh, natural_gas_kbtu, fuel_oil_kbtu, steam_kbtu, use_type_sqft)`
- If result is not all-None, merge penalty fields into result dict and add 'calculated' to data_sources
- Convert Decimal values to float before adding to result dict (psycopg2 handles float->NUMERIC fine, but Decimal objects may cause issues with JSON serialization in Streamlit)
- Save penalty data to building_metrics via upsert (just the bbl + 6 penalty fields)

**STEP 5: Narrative Generation**
- Only run if ANTHROPIC_API_KEY is available (check env var or Streamlit secrets). If not available, log warning and skip.
- Call `generate_all_narratives(result)` — result dict already has ll87_raw, energy fields, etc.
- Map narrative dict keys to DB column names:
  - "Building Envelope" -> envelope_narrative
  - "Heating System" -> heating_narrative
  - "Cooling System" -> cooling_narrative
  - "Air Distribution System" -> air_distribution_narrative
  - "Ventilation System" -> ventilation_narrative
  - "Domestic Hot Water System" -> dhw_narrative
- Save narrative data to building_metrics via upsert (just the bbl + 6 narrative fields)
- Add 'narratives' to data_sources
- Store narratives in result dict under both the original category keys AND the db column keys

Wrap Steps 4 and 5 each in their own try/except — a failure in penalty calc should NOT block narrative generation, and vice versa. Log errors but continue.

**4. Update app.py to use persisted data:**

The penalty tab (`display_penalties()`) already reads the correct field names (ghg_emissions_2024_2029, etc.) from the data dict. Since the waterfall now populates these fields, the penalty tab will work automatically when using fresh waterfall data.

For cached data path: When loading from Building_Metrics cache (`fetch_building_from_metrics`), the penalty and narrative columns will be included in the SELECT * query automatically.

Update the narrative display logic:
- When loading cached data, check if narrative columns exist in building_data (e.g., `building_data.get('envelope_narrative')`)
- If narrative columns exist and are non-empty in cached data, use them directly instead of regenerating
- Build the narratives dict from DB columns:
  ```python
  narratives = {}
  narrative_map = {
      'Building Envelope': 'envelope_narrative',
      'Heating System': 'heating_narrative',
      'Cooling System': 'cooling_narrative',
      'Air Distribution System': 'air_distribution_narrative',
      'Ventilation System': 'ventilation_narrative',
      'Domestic Hot Water System': 'dhw_narrative',
  }
  for category, col in narrative_map.items():
      val = building_data.get(col)
      if val:
          narratives[category] = val
  ```
- Only regenerate narratives (call generate_all_narratives) if no saved narratives found in DB
- Remove the unconditional narrative generation that happens after every waterfall fetch — the waterfall itself now handles this in Step 5

Update the fresh-fetch path similarly: after `fetch_building_waterfall()` returns, extract narratives from the result dict (they'll be there from Step 5), don't call generate_all_narratives again.

**5. Run schema migration:**
At the beginning of the waterfall or in app.py startup, call `migrate_add_calculation_columns()` from storage.py to ensure the 12 new columns exist. Add this as an early import/call in app.py near the top (after imports), wrapped in try/except so it only runs once and doesn't block if it fails.

IMPORTANT: When converting Decimal to float for storage, use `float(decimal_value)` — this is acceptable because psycopg2 will convert float back to NUMERIC in PostgreSQL, preserving the precision we need (2 decimal places). The Decimal precision is for intermediate calculation accuracy, not storage.
  </action>
  <verify>
1. Run `pip install backoff` and verify it installs.
2. Run `python -c "from lib.waterfall import fetch_building_waterfall; print('Import OK')"` — should import without error.
3. Test with a known BBL that has LL84 data: Run `streamlit run app.py`, enter BBL `1011190036`, verify:
   - LL97 Penalties tab shows calculated GHG emissions and penalty values (not empty)
   - System Narratives tab shows generated narratives
4. Enter the same BBL again (cache hit) — penalties and narratives should appear from cache without re-generating.
  </verify>
  <done>Waterfall runs all 5 steps. Penalty calculations and narratives persist to building_metrics. UI shows penalty values and saved narratives. Cached lookups use saved data without re-generating.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete 5-step waterfall with penalty calculations and AI narrative generation, persisted to database, displayed in UI.</what-built>
  <how-to-verify>
1. Open terminal, run: `streamlit run app.py`
2. Enter BBL `1011190036` (or any known LL97 building with LL84 data)
3. Wait for waterfall to complete (may take 30-60 seconds for narrative generation)
4. Check **LL97 Penalties** tab:
   - Should show GHG Emissions values for both 2024-2029 and 2030-2034 periods
   - Should show Emissions Limit values
   - Should show Annual Penalty amounts (may be $0 if compliant)
   - Values should be reasonable (not astronomically large or negative)
5. Check **System Narratives** tab:
   - Should show 6 expandable sections (Envelope, Heating, Cooling, Air Distribution, Ventilation, DHW)
   - Each should contain 1-2 paragraphs of professional engineering text
   - Missing data should say "not documented" (not hallucinated)
6. Enter the SAME BBL again — should load from cache instantly, penalties and narratives should appear without regeneration
7. Check a different BBL (or one without LL84 data) — penalty tab should show "No penalty data available" gracefully
  </how-to-verify>
  <resume-signal>Type "approved" or describe any issues with the penalty calculations or narratives</resume-signal>
</task>

</tasks>

<verification>
1. `pip install -r requirements.txt` installs without errors (including backoff)
2. Waterfall imports and runs: `python -c "from lib.waterfall import fetch_building_waterfall"`
3. Full waterfall for a test BBL saves penalty + narrative data to building_metrics
4. UI penalty tab displays calculated values
5. UI narrative tab displays saved narratives from DB
6. Cached data loads without re-generation
7. Missing data handled gracefully (None penalties, "not documented" narratives)
</verification>

<success_criteria>
- Waterfall executes Steps 4 (penalty calc) and 5 (narratives) after existing Steps 1-3
- Penalty results saved to building_metrics (6 NUMERIC columns)
- Narrative text saved to building_metrics (6 TEXT columns)
- UI penalty tab shows real calculated values
- UI narrative tab shows persisted narratives (not regenerated each load)
- API errors handled with backoff retry + per-narrative error isolation
- Missing energy data produces None penalties (not $0 or crashes)
- Human has verified the end-to-end flow works correctly
</success_criteria>

<output>
After completion, create `.planning/phases/03-calculations-narratives/03-02-SUMMARY.md`
</output>
