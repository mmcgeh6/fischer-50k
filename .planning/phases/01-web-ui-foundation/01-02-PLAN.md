---
phase: 01-web-ui-foundation
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - lib/database.py
  - lib/api_client.py
autonomous: true

must_haves:
  truths:
    - "Database module can connect to Supabase and query LL97/LL84/LL87 tables"
    - "Database queries return building data when BBL exists in ll97_covered_buildings"
    - "API client can generate narratives using Claude"
    - "API client handles missing data gracefully with 'not documented' fallbacks"
  artifacts:
    - path: "lib/database.py"
      provides: "Database connection and query functions"
      exports: ["fetch_building_by_bbl"]
    - path: "lib/api_client.py"
      provides: "Claude API integration for narratives"
      exports: ["generate_all_narratives", "NARRATIVE_CATEGORIES"]
  key_links:
    - from: "lib/database.py"
      to: "st.connection"
      via: "Streamlit PostgreSQL connection"
      pattern: "st\\.connection.*postgresql"
    - from: "lib/api_client.py"
      to: "anthropic.Anthropic"
      via: "Claude Messages API"
      pattern: "client\\.messages\\.create"
---

<objective>
Create the database access module and Claude API client for narrative generation.

Purpose: Build the backend modules that retrieve building data from Supabase and generate system narratives using Claude. These modules are consumed by the main Streamlit app (Plan 03).

Output: Working database.py and api_client.py modules that can be imported and used independently.
</objective>

<execution_context>
@C:\Users\minke\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\minke\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-web-ui-foundation/01-RESEARCH.md
@.planning/phases/01-web-ui-foundation/01-01-SUMMARY.md
@CLAUDE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create database module</name>
  <files>lib/database.py</files>
  <action>
Create lib/database.py following RESEARCH.md patterns and CLAUDE.md database schema.

Key implementation details from CLAUDE.md:
- ll97_covered_buildings: Primary identity source (BBL, BIN, canonical address, compliance pathway)
- ll84_data: Deduplicated energy benchmarking with pre-calculated penalties
- ll87_raw: Audit data as JSONB, query with DISTINCT ON for latest audit

```python
"""
Database module for building data retrieval.

Uses Streamlit's st.connection() for PostgreSQL access with automatic
caching, secrets management, and connection pooling.

Tables accessed:
- ll97_covered_buildings: Primary building identity (BBL, BIN, address)
- ll84_data: Energy benchmarking data with penalty calculations
- ll87_raw: LL87 energy audit data (JSONB)
"""

import streamlit as st
from typing import Optional, Dict, Any
import json


def get_connection():
    """Get PostgreSQL connection using Streamlit's connection management."""
    return st.connection("postgresql", type="sql")


def fetch_building_by_bbl(bbl: str) -> Optional[Dict[str, Any]]:
    """
    Fetch building data from all sources (LL97, LL84, LL87) for given BBL.

    This performs the data retrieval portion of the 5-step waterfall:
    1. Query LL97 Covered Buildings List for identity
    2. Query LL84 deduplicated table for energy data
    3. Query LL87 raw table for audit data

    Args:
        bbl: 10-digit BBL string

    Returns:
        Dictionary with building data from all sources, or None if not found
    """
    conn = get_connection()

    # Step 1: Get LL97 covered building info (identity, compliance pathway)
    # This is the primary source for building identity per CLAUDE.md
    ll97_query = """
        SELECT
            bbl,
            bin_preliminary as bin,
            address_canonical as address,
            compliance_pathway
        FROM ll97_covered_buildings
        WHERE bbl = :bbl
    """
    ll97_data = conn.query(ll97_query, params={"bbl": bbl}, ttl="1h")

    if ll97_data.empty:
        return None

    # Start building result dict from LL97 data
    building = ll97_data.iloc[0].to_dict()

    # Step 2: Get LL84 energy data from deduplicated table
    # Includes pre-calculated GHG emissions and penalties
    ll84_query = """
        SELECT
            year_built,
            property_gfa as gfa,
            largest_property_use_type as property_type,
            site_eui_kbtu_ft2 as site_eui,
            electricity_use_grid_purchase_kwh as electricity_kwh,
            natural_gas_use_kbtu as natural_gas_kbtu,
            fuel_oil_2_use_kbtu as fuel_oil_kbtu,
            district_steam_use_kbtu as steam_kbtu,
            total_ghg_emissions_metric_tons_co2e as total_ghg,
            ghg_emissions_2024_2029,
            emissions_limit_2024_2029,
            penalty_2024_2029,
            ghg_emissions_2030_2034,
            emissions_limit_2030_2034,
            penalty_2030_2034,
            energy_star_score
        FROM ll84_data
        WHERE bbl = :bbl
    """
    ll84_data = conn.query(ll84_query, params={"bbl": bbl}, ttl="10m")

    if not ll84_data.empty:
        # Merge LL84 data into building dict
        ll84_row = ll84_data.iloc[0].to_dict()
        building.update(ll84_row)

    # Step 3: Get LL87 audit data (latest audit, prefer 2019-2024 over 2012-2018)
    # Per CLAUDE.md: Search 2019-2024 first, fallback to 2012-2018
    ll87_query = """
        SELECT DISTINCT ON (bbl)
            bbl,
            audit_template_id,
            reporting_period,
            raw_data
        FROM ll87_raw
        WHERE bbl = :bbl
        ORDER BY bbl,
                 CASE WHEN reporting_period = '2019-2024' THEN 1 ELSE 2 END,
                 audit_template_id DESC
    """
    ll87_data = conn.query(ll87_query, params={"bbl": bbl}, ttl="1h")

    if not ll87_data.empty:
        ll87_row = ll87_data.iloc[0]
        # Store raw JSONB data for narrative generation
        raw_data = ll87_row['raw_data']
        # Handle if raw_data is already parsed or is a string
        if isinstance(raw_data, str):
            try:
                building['ll87_raw'] = json.loads(raw_data)
            except json.JSONDecodeError:
                building['ll87_raw'] = raw_data
        else:
            building['ll87_raw'] = raw_data
        building['ll87_period'] = ll87_row['reporting_period']
        building['ll87_audit_id'] = ll87_row['audit_template_id']

    return building


def get_building_count() -> int:
    """Get total count of buildings in ll97_covered_buildings table."""
    conn = get_connection()
    result = conn.query("SELECT COUNT(*) as count FROM ll97_covered_buildings", ttl="1h")
    return int(result.iloc[0]['count'])
```

Important notes:
- Use st.connection() for automatic caching and retry logic (not raw psycopg2)
- TTL caching: 1h for static data (LL97, LL87), 10m for potentially updated data (LL84)
- Column mapping accounts for different naming conventions in source tables
- LL87 raw_data is JSONB — handle both string and parsed dict cases
  </action>
  <verify>
    Cannot fully verify without secrets.toml configured.
    Syntax check: `python -c "import lib.database; print('Syntax OK')"`
  </verify>
  <done>
    - lib/database.py exists with fetch_building_by_bbl function
    - Function queries all three tables (ll97_covered_buildings, ll84_data, ll87_raw)
    - Uses st.connection() for database access (not raw psycopg2)
    - Handles missing data gracefully (returns None if BBL not found)
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Claude API client module</name>
  <files>lib/api_client.py</files>
  <action>
Create lib/api_client.py for narrative generation using Anthropic Claude.

Key implementation details from CLAUDE.md:
- 6 narrative categories: Envelope, Heating, Cooling, Air Distribution, Ventilation, DHW
- Data-only approach — no inferences, explicit "not documented" fallbacks
- Context fields: year built, use type, GFA, energy metrics
- LL87 equipment data feeds system-specific narratives

```python
"""
Claude API client for system narrative generation.

Generates 6 building system narratives using Anthropic Claude:
1. Building Envelope
2. Heating System
3. Cooling System
4. Air Distribution System
5. Ventilation System
6. Domestic Hot Water System

Uses data-only approach per CLAUDE.md — no inferences,
explicit "not documented" fallbacks for missing data.
"""

import os
import streamlit as st
from anthropic import Anthropic
from typing import Dict, Any, Optional


# Six narrative categories per CLAUDE.md
NARRATIVE_CATEGORIES = [
    "Building Envelope",
    "Heating System",
    "Cooling System",
    "Air Distribution System",
    "Ventilation System",
    "Domestic Hot Water System"
]


def get_claude_client() -> Anthropic:
    """
    Get Anthropic client with API key from environment or Streamlit secrets.

    Returns:
        Configured Anthropic client

    Raises:
        ValueError: If no API key found
    """
    api_key = os.environ.get("ANTHROPIC_API_KEY") or st.secrets.get("ANTHROPIC_API_KEY")
    if not api_key:
        raise ValueError("ANTHROPIC_API_KEY not found in environment or Streamlit secrets")
    return Anthropic(api_key=api_key)


def _extract_equipment_data(ll87_raw: Optional[Dict], category: str) -> str:
    """
    Extract relevant equipment data from LL87 raw JSONB for a specific category.

    Args:
        ll87_raw: LL87 audit data as dict
        category: Narrative category to extract for

    Returns:
        Formatted equipment description or "No equipment data available"
    """
    if not ll87_raw:
        return "No LL87 audit data available for this building."

    # Map categories to LL87 field paths
    # These field names may vary based on actual LL87 schema
    category_fields = {
        "Building Envelope": ["building_envelope", "envelope", "wall_construction", "roof_construction", "window_type"],
        "Heating System": ["heating_equipment", "boilers", "heat_exchangers", "heating_plants"],
        "Cooling System": ["cooling_equipment", "chillers", "cooling_towers", "chilled_water_plants"],
        "Air Distribution System": ["air_handling_units", "rooftop_units", "packaged_units", "ahu"],
        "Ventilation System": ["ventilation", "makeup_air_units", "doas", "energy_recovery"],
        "Domestic Hot Water System": ["domestic_hot_water", "dhw", "water_heaters"]
    }

    fields_to_check = category_fields.get(category, [])
    found_data = []

    for field in fields_to_check:
        if field in ll87_raw and ll87_raw[field]:
            found_data.append(f"{field}: {ll87_raw[field]}")

    if found_data:
        return "\n".join(found_data)
    return f"No {category.lower()} data documented in LL87 audit."


def generate_narrative(
    client: Anthropic,
    category: str,
    building_data: Dict[str, Any]
) -> str:
    """
    Generate a single system narrative using Claude.

    Args:
        client: Anthropic client instance
        category: Narrative category (e.g., "Heating System")
        building_data: Building data dict from database

    Returns:
        Generated narrative text (1-2 paragraphs)
    """
    # System prompt emphasizing data-only approach
    system_prompt = """You are a mechanical engineering expert writing concise building system narratives for energy audits.

CRITICAL RULES:
1. Write 1-2 paragraphs ONLY based on the provided data
2. If specific data is missing, explicitly state "not documented" — do NOT infer or assume
3. Focus on factual descriptions, not recommendations
4. Use professional engineering terminology
5. Be specific about equipment when data is available"""

    # Extract equipment data for this category
    equipment_data = _extract_equipment_data(
        building_data.get('ll87_raw'),
        category
    )

    # Build context from building data (per CLAUDE.md context fields)
    year_built = building_data.get('year_built', 'Not documented')
    property_type = building_data.get('property_type', 'Not documented')
    gfa = building_data.get('gfa', 0)
    electricity = building_data.get('electricity_kwh', 0)
    natural_gas = building_data.get('natural_gas_kbtu', 0)
    fuel_oil = building_data.get('fuel_oil_kbtu', 0)
    steam = building_data.get('steam_kbtu', 0)

    user_message = f"""Generate a {category} Narrative for this building.

BUILDING CONTEXT:
- Year Built: {year_built}
- Property Type: {property_type}
- Gross Floor Area: {gfa:,} sqft
- Electricity Use: {electricity:,} kWh
- Natural Gas Use: {natural_gas:,} kBtu
- Fuel Oil #2 Use: {fuel_oil:,} kBtu
- District Steam Use: {steam:,} kBtu

LL87 AUDIT DATA FOR {category.upper()}:
{equipment_data}

Write a factual 1-2 paragraph narrative about the {category.lower()}. If equipment details are not available, state that the specific systems are not documented in the available audit data."""

    message = client.messages.create(
        model="claude-sonnet-4-5-20250929",
        max_tokens=1024,
        system=system_prompt,
        temperature=0.3,  # Low temperature for analytical consistency
        messages=[
            {"role": "user", "content": user_message}
        ]
    )

    return message.content[0].text


def generate_all_narratives(building_data: Dict[str, Any]) -> Dict[str, str]:
    """
    Generate all 6 system narratives for a building.

    Args:
        building_data: Building data dict from database.fetch_building_by_bbl()

    Returns:
        Dict mapping category name to narrative text

    Raises:
        ValueError: If ANTHROPIC_API_KEY not configured
    """
    client = get_claude_client()
    narratives = {}

    for category in NARRATIVE_CATEGORIES:
        try:
            narratives[category] = generate_narrative(client, category, building_data)
        except Exception as e:
            # Store error message if narrative generation fails
            narratives[category] = f"Error generating narrative: {str(e)}"

    return narratives


def generate_single_narrative(
    building_data: Dict[str, Any],
    category: str
) -> str:
    """
    Generate a single narrative for testing or selective regeneration.

    Args:
        building_data: Building data dict
        category: One of NARRATIVE_CATEGORIES

    Returns:
        Generated narrative text

    Raises:
        ValueError: If category not in NARRATIVE_CATEGORIES
    """
    if category not in NARRATIVE_CATEGORIES:
        raise ValueError(f"Invalid category. Must be one of: {NARRATIVE_CATEGORIES}")

    client = get_claude_client()
    return generate_narrative(client, category, building_data)
```

Important notes:
- Low temperature (0.3) for analytical consistency
- Error handling per narrative (don't fail all if one fails)
- Data-only approach enforced in system prompt
- Equipment extraction is defensive (handles missing/varied field names)
  </action>
  <verify>
    Syntax check: `python -c "import lib.api_client; print('Syntax OK')"`
    Cannot fully verify without ANTHROPIC_API_KEY configured.
  </verify>
  <done>
    - lib/api_client.py exists with generate_all_narratives function
    - NARRATIVE_CATEGORIES contains all 6 categories from CLAUDE.md
    - Uses data-only approach with "not documented" fallbacks
    - Handles errors gracefully per narrative (doesn't fail entire batch)
  </done>
</task>

</tasks>

<verification>
1. Run `python -c "from lib.database import fetch_building_by_bbl; print('DB module OK')"` - syntax check
2. Run `python -c "from lib.api_client import NARRATIVE_CATEGORIES; print(NARRATIVE_CATEGORIES)"` - prints 6 categories
3. Verify both modules use st.secrets for credentials (not hardcoded)
4. Verify database.py queries all three tables mentioned in CLAUDE.md
</verification>

<success_criteria>
- Both modules pass Python syntax validation
- database.py queries ll97_covered_buildings, ll84_data, ll87_raw
- api_client.py exports NARRATIVE_CATEGORIES with 6 items
- Both modules rely on .streamlit/secrets.toml for credentials
- Error handling prevents complete failures
</success_criteria>

<output>
After completion, create `.planning/phases/01-web-ui-foundation/01-02-SUMMARY.md`
</output>
